# 成语故事短视频生成系统技术文档

## 项目概述

本系统旨在从成语列表自动生成适合儿童阅读的成语故事短视频，包含文本生成、插画制作、音频合成和视频制作等完整流程，最终发布到抖音、快手等短视频平台。

## 硬件配置分析

**您的配置：**
- **处理器**：AMD Ryzen 9 7845HX with Radeon Graphics
- **内存**：16.0 GB RAM  
- **显卡**：NVIDIA RTX 5060 Laptop

**配置评估：**
✅ 完全满足本地运行AI模型需求
✅ 16GB内存足够运行Stable Diffusion等图像生成模型
✅ RTX 5060支持CUDA加速，大幅提升图像生成速度

## 技术架构设计

### 系统模块划分

```
成语故事短视频生成系统
├── 1. 文本生成模块 (Text Generation)
│   ├── 成语列表读取
│   ├── DeepSeek API调用
│   └── 故事文本微调界面
├── 2. 图像生成模块 (Image Generation)  
│   ├── 场景提取器
│   ├── 提示词生成器
│   └── Stable Diffusion图像生成
├── 3. 音频生成模块 (Audio Generation)
│   ├── 文本分段处理
│   ├── TTS语音合成
│   └── 音频后处理
├── 4. 视频合成模块 (Video Composition)
│   ├── 图像序列处理
│   ├── 音频同步
│   └── 视频特效添加
└── 5. 发布模块 (Publishing)
    ├── 平台适配
    ├── 元数据生成
    └── 自动发布
```

## 技术选型

### 编程语言：Python 3.9+

**选择理由：**
- 丰富的AI/ML生态系统
- 优秀的图像和视频处理库
- 活跃的社区支持
- 跨平台兼容性好

### 核心依赖库

```python
# AI和机器学习
transformers>=4.30.0        # DeepSeek模型支持
diffusers>=0.20.0           # Stable Diffusion
torch>=2.0.0                # PyTorch深度学习框架
accelerate>=0.20.0          # 模型加速

# 图像处理
Pillow>=9.5.0               # 图像基础处理
opencv-python>=4.8.0        # 计算机视觉
imageio>=2.31.0             # 图像I/O

# 音频处理  
pydub>=0.25.1               # 音频处理
librosa>=0.10.0             # 音频分析
gTTS>=2.3.0                 # Google TTS (免费)

# 视频处理
moviepy>=1.0.3              # 视频编辑合成
ffmpeg-python>=0.2.0        # FFmpeg封装

# Web和API
requests>=2.31.0            # HTTP请求
streamlit>=1.25.0           # Web界面
fastapi>=0.100.0            # API服务

# 工具库
tqdm>=4.65.0                # 进度条
python-dotenv>=1.0.0        # 环境变量
loguru>=0.7.0               # 日志记录
```

## 详细实现方案

### 1. 文本生成模块

#### 1.1 DeepSeek API集成

```python
import requests
import json
from typing import List, Dict

class DeepSeekStoryGenerator:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.deepseek.com/v1/chat/completions"
        
    def generate_story(self, idiom: str) -> str:
        """生成成语故事文本"""
        prompt = f"""
        请为成语"{idiom}"创作一个适合3-8岁儿童阅读的故事，要求：
        1. 字数控制在300字以内
        2. 包含丰富的场景描述，便于后续生成插画
        3. 语言生动有趣，符合儿童认知水平
        4. 故事要有明确的开始、发展和结尾
        5. 每个场景都要有详细的视觉描述
        
        请直接输出故事内容，不要添加其他说明。
        """
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.8,
            "max_tokens": 1000
        }
        
        response = requests.post(self.base_url, headers=headers, json=data)
        result = response.json()
        
        return result["choices"][0]["message"]["content"]
```

#### 1.2 故事文本微调界面

```python
import streamlit as st

def story_editing_interface(story_text: str) -> str:
    """故事文本编辑界面"""
    st.title("成语故事文本编辑")
    
    edited_text = st.text_area(
        "编辑故事内容：",
        value=story_text,
        height=400,
        help="您可以在此修改故事内容，添加或删除场景描述"
    )
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("保存并继续", type="primary"):
            return edited_text
    
    with col2:
        if st.button("重新生成"):
            return None
            
    return story_text
```

### 2. 图像生成模块

#### 2.1 场景提取器

```python
import re
from typing import List

class SceneExtractor:
    def __init__(self):
        self.scene_patterns = [
            r'在(.+?)(?:里|中|上|下|旁|边)',
            r'(.+?)时',
            r'看到(.+?)',
            r'来到(.+?)',
            r'走进(.+?)',
            r'来到(.+?)'
        ]
    
    def extract_scenes(self, story_text: str) -> List[str]:
        """从故事文本中提取场景描述"""
        scenes = []
        sentences = re.split(r'[。！？]', story_text)
        
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 10:  # 过滤过短的句子
                for pattern in self.scene_patterns:
                    match = re.search(pattern, sentence)
                    if match:
                        scenes.append(sentence)
                        break
        
        return scenes[:15]  # 限制最多15个场景
```

#### 2.2 Stable Diffusion图像生成

```python
from diffusers import StableDiffusionPipeline
import torch
from PIL import Image

class ImageGenerator:
    def __init__(self, model_path: str = "runwayml/stable-diffusion-v1-5"):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.pipe = StableDiffusionPipeline.from_pretrained(
            model_path,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
            safety_checker=None,
            requires_safety_checker=False
        ).to(self.device)
        
        # 优化内存使用
        self.pipe.enable_memory_efficient_attention()
        self.pipe.enable_sequential_cpu_offload()
    
    def generate_image(self, prompt: str, style: str = "children_illustration") -> Image.Image:
        """生成单张插画"""
        # 构建儿童插画风格的提示词
        full_prompt = f"""
        {prompt}, 
        children's book illustration, 
        cartoon style, 
        bright colors, 
        soft lighting, 
        cute characters, 
        detailed background, 
        high quality, 
        8k resolution
        """
        
        negative_prompt = """
        realistic, adult, scary, dark, violent, 
        low quality, blurry, distorted
        """
        
        image = self.pipe(
            full_prompt,
            negative_prompt=negative_prompt,
            num_inference_steps=30,
            guidance_scale=7.5,
            width=512,
            height=512
        ).images[0]
        
        return image
    
    def generate_story_images(self, scenes: List[str]) -> List[Image.Image]:
        """为故事场景生成插画序列"""
        images = []
        
        for i, scene in enumerate(scenes):
            print(f"正在生成第 {i+1}/{len(scenes)} 张插画...")
            image = self.generate_image(scene)
            images.append(image)
            
        return images
```

### 3. 音频生成模块

#### 3.1 文本分段处理

```python
import re
from typing import List, Dict

class TextSegmenter:
    def __init__(self):
        self.dialogue_pattern = r'["""](.*?)["""]'
        self.narration_markers = ['说', '想', '看', '听', '走', '来', '去']
    
    def segment_text(self, story_text: str) -> List[Dict]:
        """将故事文本分段为旁白和对话"""
        segments = []
        sentences = re.split(r'[。！？]', story_text)
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            # 检查是否为对话
            dialogue_match = re.search(self.dialogue_pattern, sentence)
            if dialogue_match:
                segments.append({
                    'type': 'dialogue',
                    'text': dialogue_match.group(1),
                    'full_sentence': sentence
                })
            else:
                segments.append({
                    'type': 'narration',
                    'text': sentence,
                    'full_sentence': sentence
                })
        
        return segments
```

#### 3.2 TTS语音合成

```python
from gtts import gTTS
import pygame
import io
from pydub import AudioSegment
from pydub.effects import normalize

class AudioGenerator:
    def __init__(self):
        self.narration_voice = 'zh-cn'  # 旁白使用标准中文
        self.character_voice = 'zh-cn'  # 角色配音
        
    def text_to_speech(self, text: str, voice_type: str = 'narration') -> AudioSegment:
        """文本转语音"""
        try:
            # 使用gTTS生成语音
            tts = gTTS(text=text, lang='zh-cn', slow=False)
            
            # 保存到内存
            audio_buffer = io.BytesIO()
            tts.write_to_fp(audio_buffer)
            audio_buffer.seek(0)
            
            # 转换为AudioSegment
            audio = AudioSegment.from_mp3(audio_buffer)
            
            # 音频后处理
            if voice_type == 'dialogue':
                # 对话音频稍微加速和调整音调
                audio = audio.speedup(playback_speed=1.1)
                audio = audio._spawn(audio.raw_data, overrides={
                    "frame_rate": int(audio.frame_rate * 1.05)
                })
            
            return normalize(audio)
            
        except Exception as e:
            print(f"TTS生成失败: {e}")
            # 返回静音作为备用
            return AudioSegment.silent(duration=len(text) * 100)
    
    def generate_story_audio(self, segments: List[Dict]) -> AudioSegment:
        """生成完整故事音频"""
        audio_segments = []
        
        for segment in segments:
            audio = self.text_to_speech(
                segment['text'], 
                segment['type']
            )
            
            # 在对话后添加短暂停顿
            if segment['type'] == 'dialogue':
                audio += AudioSegment.silent(duration=500)
            
            audio_segments.append(audio)
        
        # 合并所有音频片段
        full_audio = sum(audio_segments)
        
        # 添加背景音乐（可选）
        return full_audio
```

### 4. 视频合成模块

#### 4.1 视频合成器

```python
from moviepy.editor import *
import os
from typing import List

class VideoComposer:
    def __init__(self, output_width: int = 1080, output_height: int = 1920):
        self.output_size = (output_width, output_height)
        
    def create_story_video(self, images: List[Image.Image], audio: AudioSegment, 
                          output_path: str) -> str:
        """创建故事视频"""
        
        # 保存音频文件
        audio_path = "temp_audio.wav"
        audio.export(audio_path, format="wav")
        
        # 计算每张图片的显示时间
        audio_duration = len(audio) / 1000.0  # 转换为秒
        image_duration = audio_duration / len(images)
        
        # 创建图片剪辑列表
        clips = []
        for i, image in enumerate(images):
            # 保存图片
            img_path = f"temp_image_{i}.png"
            image.save(img_path)
            
            # 创建图片剪辑
            clip = ImageClip(img_path, duration=image_duration)
            
            # 调整图片尺寸以适应输出尺寸
            clip = clip.resize(self.output_size)
            
            clips.append(clip)
        
        # 拼接所有图片剪辑
        video = concatenate_videoclips(clips, method="compose")
        
        # 添加音频
        audio_clip = AudioFileClip(audio_path)
        final_video = video.set_audio(audio_clip)
        
        # 导出视频
        final_video.write_videofile(
            output_path,
            fps=24,
            codec='libx264',
            audio_codec='aac',
            temp_audiofile='temp-audio.m4a',
            remove_temp=True
        )
        
        # 清理临时文件
        self._cleanup_temp_files(images, audio_path)
        
        return output_path
    
    def _cleanup_temp_files(self, images: List[Image.Image], audio_path: str):
        """清理临时文件"""
        try:
            os.remove(audio_path)
            for i in range(len(images)):
                img_path = f"temp_image_{i}.png"
                if os.path.exists(img_path):
                    os.remove(img_path)
        except Exception as e:
            print(f"清理临时文件时出错: {e}")
```

### 5. 发布模块

#### 5.1 平台发布器

```python
import json
from datetime import datetime

class PlatformPublisher:
    def __init__(self):
        self.platforms = {
            'douyin': {
                'name': '抖音',
                'video_format': 'mp4',
                'max_duration': 60,
                'recommended_size': (1080, 1920)
            },
            'kuaishou': {
                'name': '快手', 
                'video_format': 'mp4',
                'max_duration': 60,
                'recommended_size': (1080, 1920)
            }
        }
    
    def generate_metadata(self, idiom: str, story_text: str) -> Dict:
        """生成发布元数据"""
        return {
            'title': f'成语故事：{idiom}',
            'description': f'今天给大家讲一个关于"{idiom}"的精彩故事！适合3-8岁的小朋友观看，寓教于乐，让孩子在故事中学习传统文化。\n\n#成语故事 #儿童教育 #传统文化 #亲子时光',
            'tags': ['成语故事', '儿童教育', '传统文化', '亲子时光', idiom],
            'category': '教育',
            'privacy': 'public'
        }
    
    def prepare_for_publishing(self, video_path: str, metadata: Dict) -> Dict:
        """准备发布文件"""
        return {
            'video_file': video_path,
            'metadata': metadata,
            'upload_time': datetime.now().isoformat(),
            'status': 'ready_for_upload'
        }
```

## 主程序流程

### 完整的工作流程

```python
import streamlit as st
from typing import List, Optional

class IdiomStoryVideoGenerator:
    def __init__(self):
        self.story_generator = DeepSeekStoryGenerator(api_key="your_deepseek_api_key")
        self.scene_extractor = SceneExtractor()
        self.image_generator = ImageGenerator()
        self.text_segmenter = TextSegmenter()
        self.audio_generator = AudioGenerator()
        self.video_composer = VideoComposer()
        self.publisher = PlatformPublisher()
    
    def process_idiom(self, idiom: str) -> str:
        """处理单个成语的完整流程"""
        
        # 步骤1：生成故事文本
        st.info(f"正在为成语'{idiom}'生成故事...")
        story_text = self.story_generator.generate_story(idiom)
        
        # 步骤2：用户微调界面
        st.info("请检查并编辑故事内容")
        edited_story = story_editing_interface(story_text)
        
        if edited_story is None:
            return self.process_idiom(idiom)  # 重新生成
        
        # 步骤3：提取场景
        st.info("正在提取故事场景...")
        scenes = self.scene_extractor.extract_scenes(edited_story)
        
        # 步骤4：生成插画
        st.info("正在生成插画...")
        progress_bar = st.progress(0)
        images = []
        for i, scene in enumerate(scenes):
            image = self.image_generator.generate_image(scene)
            images.append(image)
            progress_bar.progress((i + 1) / len(scenes))
        
        # 步骤5：生成音频
        st.info("正在生成音频...")
        segments = self.text_segmenter.segment_text(edited_story)
        audio = self.audio_generator.generate_story_audio(segments)
        
        # 步骤6：合成视频
        st.info("正在合成视频...")
        output_path = f"output/{idiom}_story.mp4"
        video_path = self.video_composer.create_story_video(
            images, audio, output_path
        )
        
        # 步骤7：准备发布
        metadata = self.publisher.generate_metadata(idiom, edited_story)
        publish_info = self.publisher.prepare_for_publishing(video_path, metadata)
        
        st.success(f"视频生成完成！保存路径：{video_path}")
        
        return video_path
    
    def batch_process(self, idioms: List[str]):
        """批量处理成语列表"""
        results = []
        
        for idiom in idioms:
            try:
                video_path = self.process_idiom(idiom)
                results.append({
                    'idiom': idiom,
                    'video_path': video_path,
                    'status': 'success'
                })
            except Exception as e:
                st.error(f"处理成语'{idiom}'时出错：{e}")
                results.append({
                    'idiom': idiom,
                    'video_path': None,
                    'status': 'failed',
                    'error': str(e)
                })
        
        return results

# Streamlit主界面
def main():
    st.set_page_config(
        page_title="成语故事短视频生成器",
        page_icon="📚",
        layout="wide"
    )
    
    st.title("📚 成语故事短视频生成器")
    st.markdown("---")
    
    generator = IdiomStoryVideoGenerator()
    
    # 侧边栏配置
    with st.sidebar:
        st.header("配置设置")
        
        # API密钥输入
        api_key = st.text_input("DeepSeek API密钥", type="password")
        
        # 成语输入方式选择
        input_method = st.radio(
            "选择输入方式",
            ["单个成语", "成语列表", "从文件读取"]
        )
        
        idioms = []
        
        if input_method == "单个成语":
            idiom = st.text_input("输入成语")
            if idiom:
                idioms = [idiom]
        
        elif input_method == "成语列表":
            idiom_text = st.text_area("输入成语列表（每行一个）")
            if idiom_text:
                idioms = [line.strip() for line in idiom_text.split('\n') if line.strip()]
        
        else:  # 从文件读取
            uploaded_file = st.file_uploader("上传成语文件", type=['txt', 'csv'])
            if uploaded_file:
                content = uploaded_file.read().decode('utf-8')
                idioms = [line.strip() for line in content.split('\n') if line.strip()]
    
    # 主界面
    if idioms and api_key:
        if st.button("开始生成", type="primary"):
            if len(idioms) == 1:
                # 单个成语处理
                generator.process_idiom(idioms[0])
            else:
                # 批量处理
                results = generator.batch_process(idioms)
                
                # 显示结果
                st.header("处理结果")
                for result in results:
                    if result['status'] == 'success':
                        st.success(f"✅ {result['idiom']} - 生成成功")
                    else:
                        st.error(f"❌ {result['idiom']} - 生成失败：{result['error']}")
    
    else:
        st.info("请在侧边栏配置API密钥和输入成语")

if __name__ == "__main__":
    main()
```

## 环境配置

### 1. 系统要求

```bash
# Python 3.9+
# CUDA 11.8+ (用于GPU加速)
# FFmpeg (用于视频处理)
```

### 2. 安装依赖

```bash
# 创建虚拟环境
python -m venv idiom_story_env
source idiom_story_env/bin/activate  # Linux/Mac
# idiom_story_env\Scripts\activate   # Windows

# 安装PyTorch (CUDA版本)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 安装其他依赖
pip install -r requirements.txt

# 安装FFmpeg
# Windows: 下载并添加到PATH
# Linux: sudo apt install ffmpeg
# Mac: brew install ffmpeg
```

### 3. 配置文件

创建 `.env` 文件：

```env
# DeepSeek API配置
DEEPSEEK_API_KEY=your_api_key_here
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

# 模型配置
SD_MODEL_PATH=runwayml/stable-diffusion-v1-5
OUTPUT_DIR=./output
TEMP_DIR=./temp

# 视频配置
VIDEO_WIDTH=1080
VIDEO_HEIGHT=1920
VIDEO_FPS=24
AUDIO_SAMPLE_RATE=44100

# 日志配置
LOG_LEVEL=INFO
LOG_FILE=./logs/app.log
```

## 使用说明

### 1. 启动应用

```bash
# 启动Streamlit界面
streamlit run main.py

# 或启动API服务
python api_server.py
```

### 2. 基本使用流程

1. **配置API密钥**：在侧边栏输入DeepSeek API密钥
2. **输入成语**：选择输入方式并输入成语
3. **生成故事**：系统自动调用DeepSeek生成故事文本
4. **编辑文本**：在编辑界面中微调故事内容
5. **生成插画**：系统提取场景并生成15张插画
6. **合成音频**：生成旁白和角色配音
7. **制作视频**：将插画和音频合成为短视频
8. **准备发布**：生成发布元数据和标签

### 3. 高级功能

- **批量处理**：支持同时处理多个成语
- **自定义风格**：可调整插画风格和音频效果
- **质量优化**：支持不同质量的输出设置
- **自动发布**：集成平台发布功能（需要额外配置）

## 性能优化建议

### 1. 硬件优化

```python
# GPU内存优化
torch.cuda.empty_cache()  # 定期清理GPU缓存
torch.backends.cudnn.benchmark = True  # 启用cuDNN自动调优

# 模型量化（减少显存占用）
pipe = pipe.to("cpu")
pipe = pipe.half()  # 使用半精度浮点数
```

### 2. 批处理优化

```python
# 批量生成图像
def batch_generate_images(self, prompts: List[str], batch_size: int = 4):
    """批量生成图像以提高效率"""
    images = []
    for i in range(0, len(prompts), batch_size):
        batch_prompts = prompts[i:i+batch_size]
        batch_images = self.pipe(batch_prompts).images
        images.extend(batch_images)
    return images
```

### 3. 缓存机制

```python
import hashlib
import pickle
from pathlib import Path

class CacheManager:
    def __init__(self, cache_dir: str = "./cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
    
    def get_cache_key(self, content: str) -> str:
        """生成缓存键"""
        return hashlib.md5(content.encode()).hexdigest()
    
    def get_cached_result(self, key: str):
        """获取缓存结果"""
        cache_file = self.cache_dir / f"{key}.pkl"
        if cache_file.exists():
            with open(cache_file, 'rb') as f:
                return pickle.load(f)
        return None
    
    def save_cache(self, key: str, result):
        """保存缓存"""
        cache_file = self.cache_dir / f"{key}.pkl"
        with open(cache_file, 'wb') as f:
            pickle.dump(result, f)
```

## 部署方案

### 1. 本地部署

```bash
# 使用Docker部署
docker build -t idiom-story-generator .
docker run -p 8501:8501 -v $(pwd)/output:/app/output idiom-story-generator
```

### 2. 云服务器部署

```yaml
# docker-compose.yml
version: '3.8'
services:
  web:
    build: .
    ports:
      - "8501:8501"
    volumes:
      - ./output:/app/output
      - ./cache:/app/cache
    environment:
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## 扩展功能

### 1. 多语言支持

```python
class MultiLanguageSupport:
    def __init__(self):
        self.languages = {
            'zh': '中文',
            'en': 'English',
            'ja': '日本語'
        }
    
    def translate_story(self, story: str, target_lang: str) -> str:
        """翻译故事文本"""
        # 使用翻译API或模型
        pass
```

### 2. 互动功能

```python
class InteractiveFeatures:
    def add_quiz_questions(self, story: str) -> List[Dict]:
        """为故事添加互动问题"""
        # 生成与故事相关的问题
        pass
    
    def create_character_voices(self, characters: List[str]) -> Dict:
        """为不同角色创建独特的语音"""
        # 使用不同的TTS音色
        pass
```

### 3. 数据分析

```python
class Analytics:
    def track_generation_stats(self):
        """跟踪生成统计"""
        pass
    
    def analyze_content_performance(self):
        """分析内容表现"""
        pass
```

## 注意事项

### 1. 版权和法律

- 确保生成的成语故事不侵犯版权
- 遵守各平台的内容政策
- 注意儿童内容的安全性和适宜性

### 2. 性能监控

- 监控GPU内存使用情况
- 定期清理临时文件
- 优化模型加载时间

### 3. 错误处理

```python
class ErrorHandler:
    def handle_generation_error(self, error: Exception, context: str):
        """统一错误处理"""
        logger.error(f"生成错误 [{context}]: {error}")
        # 发送错误通知
        # 记录错误统计
```

## 总结

本技术文档提供了一个完整的成语故事短视频生成系统方案，充分利用您的硬件配置和现有的DeepSeek接口。系统采用模块化设计，易于维护和扩展，能够高效地生成高质量的儿童教育内容。

通过合理的优化和缓存机制，系统可以在您的配置下稳定运行，为创作优质的成语故事短视频提供强有力的技术支持。
